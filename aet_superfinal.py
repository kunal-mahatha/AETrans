# -*- coding: utf-8 -*-
"""AET-SUPERFINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CS5TLgpixlrKIMlTzk8amjIFdEogLYZF
"""

import torch
import torch.nn as nn
from sklearn.cluster import KMeans
from torch.utils.data import Subset
import numpy as np


class AutoEncoder(nn.Module):
    def __init__(self):
        super(AutoEncoder, self).__init__()

        # Encoder layers
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)

        # Decoder layers
        self.deconv1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.deconv2 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.deconv3 = nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)

        x = self.deconv1(x)
        x = self.deconv2(x)
        x = self.deconv3(x)

        return x


    def encoder(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        return x

import torch
from torchvision import datasets, transforms

# Define the transform to normalize the data
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Load the CIFAR-10 dataset
cifar10_train = datasets.CIFAR10(root='path/to/data', train=True, download=True, transform=transform)
cifar10_test = datasets.CIFAR10(root='path/to/data', train=False, download=True, transform=transform)

# Define the indices of the images to use
indices = list(range(600))
# Create the subset of the dataset
subset_train = Subset(cifar10_train, indices)
subset_test = Subset(cifar10_test, indices)

# Create the DataLoader
train_loader = torch.utils.data.DataLoader(subset_train, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(subset_test, batch_size=64, shuffle=True)

# Initialize the model and move it to the GPU
model = AutoEncoder()

# Move the model to multiple GPUs
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)

if torch.cuda.is_available():
    model = model.cuda()

# Define the criterion and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
num_epochs=2
print("Training Started...")
# Training loop
for epoch in range(num_epochs):
    train_loss = 0.0
    train_acc = 0.0
    for data, _ in train_loader:
        # Move the data to the GPU
        if torch.cuda.is_available():
            data = data.cuda()

        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, data)
        loss.backward()
        optimizer.step()

        # Accumulate the training loss and accuracy
        train_loss += loss.item()
        train_acc += (output == data).sum().item() / len(data)

    # Print the epoch, loss, and accuracy
    train_loss /= len(train_loader)
    train_acc /= len(train_loader)
    print(f'Epoch {epoch+1} - Loss: {train_loss:.4f} - Accuracy: {train_acc:.4f}')

# Initialize an empty list to store the encoded vectors
encoded_vectors = []

# Iterate through the dataset
for data, _ in train_loader:
    # Move the data to the GPU
    if torch.cuda.is_available():
        data = data.cuda()
    # Pass the data through the encoder
    encoder_output = model.encoder(data)
    # Flatten the encoded output
    encoder_output = encoder_output.view(encoder_output.size(0), -1)
    # Append the encoded vectors to the list
    encoded_vectors.append(encoder_output.cpu().detach().numpy())

# Concatenate all the encoded vectors into a single array
encoded_vectors = np.concatenate(encoded_vectors, axis=0)

codebook_size=10 #use large number here

# Initialize the k-means model
kmeans = KMeans(n_clusters=codebook_size)

# Fit the k-means model to the encoded vectors
kmeans.fit(encoded_vectors)

# Access the codebook
codebook = kmeans.cluster_centers_

from sklearn.metrics import pairwise_distances

# Compute the pairwise distances between the encoded vectors and the codebook vectors
distances = pairwise_distances(encoded_vectors, codebook)

# Assign each encoded vector to its nearest codebook vector
codebook_assignments = np.argmin(distances, axis=1)

# Create a dictionary to store the labels for each codebook vector
codebook_labels = {}

# Iterate through the dataset
for _, labels in train_loader:
    # Iterate through the encoded vectors
    for i, label in enumerate(labels):
        # Get the codebook assignment for this vector
        codebook_vector = codebook_assignments[i]
        # Update the labels for this codebook vector
        if codebook_vector in codebook_labels:
            codebook_labels[codebook_vector].append(label)
        else:
            codebook_labels[codebook_vector] = [label]

# Create a new dataset containing the codebook vectors and their labels
codebook_dataset = []
for i in range(codebook_size):
    # Get the most common label for this codebook vector
    label = max(codebook_labels[i], key=codebook_labels[i].count)
    # Append the codebook vector and its label to the dataset
    codebook_dataset.append((codebook[i], label))

codebook_vectors_dense = np.array([vector for vector, _ in codebook_dataset])

from sklearn.preprocessing import LabelEncoder

# Initialize the LabelEncoder
le = LabelEncoder()

# Fit the LabelEncoder to the labels
le.fit([label for _, label in codebook_dataset])

# Transform the labels
labels = le.transform([label for _, label in codebook_dataset])

import torch
from torch.utils.data import Dataset, DataLoader

class CodebookDataset(Dataset):
    def __init__(self, codebook_vectors, labels):
        self.codebook_vectors = codebook_vectors
        self.labels = labels

    def __len__(self):
        return len(self.codebook_vectors)

    def __getitem__(self, idx):
        codebook_vector = self.codebook_vectors[idx]
        label = self.labels[idx]
        return codebook_vector, label

# Instantiate the dataset
codebook_vectors_dense = np.array([vector for vector, _ in codebook_dataset])
labels = np.array([label for _, label in codebook_dataset])
dataset = CodebookDataset(codebook_vectors_dense, labels)

# Define the DataLoader
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

import torch
import torch.nn as nn

class TransformerClassifier(nn.Module):
    def __init__(self, input_size, output_size, hidden_size, num_layers, num_heads):
        super(TransformerClassifier, self).__init__()

        self.embedding = nn.Embedding(input_size, hidden_size)
        self.transformer = nn.Transformer(hidden_size, num_layers, num_heads)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.embedding(x)
        x, _ = self.transformer(x, x)
        x = self.fc(x[:, -1, :])
        return x

# Define the model
input_size = len(codebook_vectors_dense)
output_size = len(set(labels))
hidden_size = 64
num_layers = 2
num_heads = 4

model = TransformerClassifier(input_size, output_size, hidden_size, num_layers, num_heads)

# Define the criterion and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Move the model to multiple GPUs
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)

if torch.cuda.is_available():
    model = model.cuda()

# Number of training epochs
num_epochs = 10

# Training loop
for epoch in range(num_epochs):
    train_loss = 0.0
    train_acc = 0.0
    for data, labels in dataloader:
        # Move the data to the GPU
        if torch.cuda.is_available():
            data = data.cuda()
            labels = labels.cuda()

        # Convert data to LongTensor
        data = data.long()
        
        # zero the gradients
        optimizer.zero_grad()
        # forward pass
        output = model(data)
        # calculate the loss
        loss = criterion(output, labels)
        # backward pass and optimization
        loss.backward()
        optimizer.step()
        # update the loss and accuracy
        train_loss += loss.item()
        train_acc += (output.argmax(1) == labels).float().mean().item()
    # Print the average training loss and accuracy for the epoch
    train_loss /= len(dataloader)
    train_acc /= len(dataloader)
    print(f'Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f} - Acc: {train_acc:.4f}')

